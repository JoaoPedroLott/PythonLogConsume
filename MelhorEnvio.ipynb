{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação de LOGs para MySQL e geeração de relatórios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeiramente vamos importar as bibliotecas necessárias. Após este passo vamos ler o arquivo e criar um pandas dataframe com ele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar as bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import json\n",
    "import mysql.connector\n",
    "from mysql.connector import errorcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define meu arquivo de log\n",
    "file = 'logs.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Le o arquivo e salva na variavel Log\n",
    "log = []\n",
    "for line in open(file, 'r'):\n",
    "    log.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria um id para o log baseando no indice\n",
    "df['id'] = df.index+1\n",
    "\n",
    "#Exibe as 5 primeiras linhas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Após o dataframe criado vamos criar novos dataframes para separar os dados dos logs\n",
    "\n",
    "##### Request, Response, Route, Service e Latencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cria um novo Dataframe com os Requests\n",
    "df_request = (\n",
    "    df[\"request\"]\n",
    "    .apply(pd.Series)\n",
    "    .merge(df['id'], left_index=True, right_index = True)\n",
    ")\n",
    "\n",
    "# Elimina a coluna do Dataframe principal\n",
    "df.drop(['request'], axis='columns', inplace=True)\n",
    "\n",
    "# Extrair os dados do header\n",
    "df_request = (\n",
    "    df_request[\"headers\"]\n",
    "    .apply(pd.Series)\n",
    "    .merge(df_request, left_index=True, right_index = True)\n",
    ")\n",
    "\n",
    "#Elimina a coluna \n",
    "df_request.drop(['headers'], axis='columns', inplace=True)\n",
    "\n",
    "# Renomeia a coluna\n",
    "df_request = df_request.rename(columns = {'id': 'log_id'}, inplace = False)\n",
    "\n",
    "# Transforma a coluna com lista em string\n",
    "df_request['querystring'] = [','.join(map(str, l)) for l in df_request['querystring']]\n",
    "\n",
    "# Exibe os 5 primeiros registros\n",
    "df_request.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um novo Dataframe com o Response\n",
    "df_response = (\n",
    "    df[\"response\"]\n",
    "    .apply(pd.Series)\n",
    "    .merge(df['id'], left_index=True, right_index = True)\n",
    ")\n",
    "\n",
    "# Elimina a coluna do Dataframe principal\n",
    "df.drop(['response'], axis='columns', inplace=True)\n",
    "\n",
    "# Extrair os dados do header\n",
    "df_response = (\n",
    "    df_response[\"headers\"]\n",
    "    .apply(pd.Series)\n",
    "    .merge(df_response, left_index=True, right_index = True)\n",
    ")\n",
    "\n",
    "# Elimina a coluna \n",
    "df_response.drop(['headers'], axis='columns', inplace=True)\n",
    "\n",
    "# Renomeia a coluna\n",
    "df_response = df_response.rename(columns = {'id': 'log_id'}, inplace = False)\n",
    "\n",
    "# Exibe os 5 primeiros registros\n",
    "df_response.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um novo Dataframe com a Rota\n",
    "df_route = (\n",
    "    df[\"route\"]\n",
    "    .apply(pd.Series)\n",
    "    .merge(df['id'], left_index=True, right_index = True)\n",
    ")\n",
    "\n",
    "# Elimina a coluna do Dataframe principal\n",
    "df.drop(['route'], axis='columns', inplace=True)\n",
    "\n",
    "# Extrair os dados do header\n",
    "df_route = (\n",
    "    df_route[\"service\"]\n",
    "    .apply(pd.Series)\n",
    "    .merge(df_route, left_index=True, right_index = True)\n",
    ")\n",
    "\n",
    "# Elimina a coluna \n",
    "df_route.drop(['service'], axis='columns', inplace=True)\n",
    "\n",
    "# Renomeia as colunas\n",
    "df_route = df_route.rename(columns = {'id': 'service_id', 'id_x': 'route_id', 'id_y': 'log_id'}, inplace = False)\n",
    "\n",
    "# Transforma as colunas com listas em strings\n",
    "df_route['paths'] = [','.join(map(str, l)) for l in df_route['paths']]\n",
    "df_route['methods'] = [','.join(map(str, l)) for l in df_route['methods']]\n",
    "df_route['protocols'] = [','.join(map(str, l)) for l in df_route['protocols']]\n",
    "\n",
    "# Exibe os 5 primeiros registros\n",
    "df_route.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um novo Dataframe com o Service\n",
    "df_service = (\n",
    "    df[\"service\"]\n",
    "    .apply(pd.Series)\n",
    "    .merge(df['id'], left_index=True, right_index = True)\n",
    ")\n",
    "\n",
    "# Elimina a coluna do Dataframe principal\n",
    "df.drop(['service'], axis='columns', inplace=True)\n",
    "\n",
    "# Renomeia a coluna\n",
    "df_service = df_service.rename(columns = {'id_y': 'log_id', 'id_x': 'service_id'}, inplace = False)\n",
    "\n",
    "# Exibe os 5 primeiros registros\n",
    "df_service.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um novo Dataframe com a latencies\n",
    "df_latencies = (\n",
    "    df[\"latencies\"]\n",
    "    .apply(pd.Series)\n",
    "    .merge(df['id'], left_index=True, right_index = True)\n",
    ")\n",
    "\n",
    "# Elimina a coluna do Dataframe principal\n",
    "df.drop(['latencies'], axis='columns', inplace=True)\n",
    "\n",
    "# Renomeia a coluna\n",
    "df_latencies = df_latencies.rename(columns = {'id': 'log_id'}, inplace = False)\n",
    "\n",
    "# Exibe os 5 primeiros registros\n",
    "df_latencies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair os dados do authenticated_entity\n",
    "df = (\n",
    "    df[\"authenticated_entity\"]\n",
    "    .apply(pd.Series)\n",
    "    .merge(df, left_index=True, right_index = True)\n",
    ")\n",
    "\n",
    "# Elimina a coluna\n",
    "df.drop(['authenticated_entity'], axis='columns', inplace=True)\n",
    "\n",
    "# Extrair os dados do consumer_id\n",
    "df = (\n",
    "    df[\"consumer_id\"]\n",
    "    .apply(pd.Series)\n",
    "    .merge(df, left_index=True, right_index = True)\n",
    ")\n",
    "\n",
    "# Elimina a coluna\n",
    "df.drop(['consumer_id'], axis='columns', inplace=True)\n",
    "\n",
    "# Renomeia a coluna\n",
    "df = df.rename(columns = {'uuid': 'consumer_id'}, inplace = False)\n",
    "\n",
    "# Exibe as 5 primeiras linhas do dataframe original\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Após termos criado todos os dataframes vamos criar uma conexão com o banco de dados MySQL e criar as tabelas do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria a conexão com o banco e inicializa o cursor\n",
    "cnx = mysql.connector.connect(user='root', password='root',host='127.0.0.1')\n",
    "cursor = cnx.cursor()\n",
    "print(\"Conectado com sucesso.................................\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o nome do database\n",
    "DB_NAME = 'melhor_envio'\n",
    "\n",
    "# Scripts para criar as tabelas\n",
    "TABLES = {}\n",
    "TABLES['log'] = (\n",
    "    \"CREATE TABLE `log` (\"\n",
    "    \"  `id` int(11) NOT NULL,\"\n",
    "    \"  `consumer_id` varchar(50) NOT NULL,\"\n",
    "    \"  `upstream_uri` varchar(50) NOT NULL,\"\n",
    "    \"  `client_ip` varchar(20) NOT NULL,\"\n",
    "    \"  `started_at` varchar(50) NOT NULL,\"\n",
    "    \"  PRIMARY KEY (`id`)\"\n",
    "    \") ENGINE=InnoDB\")\n",
    "\n",
    "TABLES['log_request'] = (\n",
    "    \"CREATE TABLE `log_request` (\"\n",
    "    \"  `id` int(11) NOT NULL AUTO_INCREMENT,\"\n",
    "    \"  `log_id` int(11) NOT NULL,\"\n",
    "    \"  `method` varchar(20) NOT NULL,\"\n",
    "    \"  `uri` varchar(50) NOT NULL,\"\n",
    "    \"  `url` varchar(100) NOT NULL,\"\n",
    "    \"  `size` int(11) NOT NULL,\"\n",
    "    \"  `querystring` varchar(100) NOT NULL,\"\n",
    "    \"  `accept` varchar(50) NOT NULL,\"\n",
    "    \"  `host` varchar(100) NOT NULL,\"\n",
    "    \"  `user_agent` varchar(50) NOT NULL,\"\n",
    "    \"  CONSTRAINT `request_log_fk` FOREIGN KEY (`log_id`) \"\n",
    "    \"     REFERENCES `log` (`id`) ON DELETE CASCADE,\"\n",
    "    \"  PRIMARY KEY (`id`)\"\n",
    "    \") ENGINE=InnoDB\")\n",
    "\n",
    "TABLES['log_response'] = (\n",
    "    \"CREATE TABLE `log_response` (\"\n",
    "    \"  `id` int(11) NOT NULL AUTO_INCREMENT,\"\n",
    "    \"  `log_id` int(11) NOT NULL,\"\n",
    "    \"  `status` int(11) NOT NULL,\"\n",
    "    \"  `size` int(11) NOT NULL,\"\n",
    "    \"  `content_length` int(11) NOT NULL,\"\n",
    "    \"  `via` varchar(40) NOT NULL,\"\n",
    "    \"  `connection` varchar(20) NOT NULL,\"\n",
    "    \"  `access_control_allow_credentials` varchar(20) NOT NULL,\"\n",
    "    \"  `content_type` varchar(40) NOT NULL,\"\n",
    "    \"  `server` varchar(40) NOT NULL,\"\n",
    "    \"  `access_control_allow_origin` varchar(40) NOT NULL,\"\n",
    "    \"  CONSTRAINT `response_log_fk` FOREIGN KEY (`log_id`) \"\n",
    "    \"     REFERENCES `log` (`id`) ON DELETE CASCADE,\"\n",
    "    \"  PRIMARY KEY (`id`)\"\n",
    "    \") ENGINE=InnoDB\")\n",
    "\n",
    "TABLES['log_route'] = (\n",
    "    \"CREATE TABLE `log_route` (\"\n",
    "    \"  `id` int(11) NOT NULL AUTO_INCREMENT,\"\n",
    "    \"  `log_id` int(11) NOT NULL,\"\n",
    "    \"  `created_at` varchar(40) NOT NULL,\"\n",
    "    \"  `hosts` varchar(100) NOT NULL,\"\n",
    "    \"  `route_id` varchar(100) NOT NULL,\"\n",
    "    \"  `methods` varchar(100) NOT NULL,\"\n",
    "    \"  `paths` varchar(100) NOT NULL,\"\n",
    "    \"  `preserve_host` varchar(10) NOT NULL,\"\n",
    "    \"  `protocols` varchar(40) NOT NULL,\"\n",
    "    \"  `regex_priority` integer(11) NOT NULL,\"\n",
    "    \"  `service_id` varchar(100) NOT NULL,\"\n",
    "    \"  `strip_path` varchar(40) NOT NULL,\"\n",
    "    \"  `updated_at` varchar(40) NOT NULL,\"\n",
    "    \"  CONSTRAINT `route_log_fk` FOREIGN KEY (`log_id`) \"\n",
    "    \"     REFERENCES `log` (`id`) ON DELETE CASCADE,\"\n",
    "    \"  PRIMARY KEY (`id`)\"\n",
    "    \") ENGINE=InnoDB\")\n",
    "\n",
    "TABLES['log_service'] = (\n",
    "    \"CREATE TABLE `log_service` (\"\n",
    "    \"  `id` int(11) NOT NULL AUTO_INCREMENT,\"\n",
    "    \"  `log_id` int(11) NOT NULL,\"\n",
    "    \"  `connect_timeout` integer(11) NOT NULL,\"\n",
    "    \"  `created_at` varchar(40) NOT NULL,\"\n",
    "    \"  `host` varchar(100) NOT NULL,\"\n",
    "    \"  `service_id` varchar(100) NOT NULL,\"\n",
    "    \"  `name` varchar(50) NOT NULL,\"\n",
    "    \"  `path` varchar(50) NOT NULL,\"\n",
    "    \"  `port` varchar(10) NOT NULL,\"\n",
    "    \"  `protocol` varchar(40) NOT NULL,\"\n",
    "    \"  `read_timeout` integer(11) NOT NULL,\"\n",
    "    \"  `retries` integer(11) NOT NULL,\"\n",
    "    \"  `updated_at` varchar(40) NOT NULL,\"\n",
    "    \"  `write_timeout` integer(11) NOT NULL,\"\n",
    "    \"  CONSTRAINT `service_log_fk` FOREIGN KEY (`log_id`) \"\n",
    "    \"     REFERENCES `log` (`id`) ON DELETE CASCADE,\"\n",
    "    \"  PRIMARY KEY (`id`)\"\n",
    "    \") ENGINE=InnoDB\")\n",
    "\n",
    "TABLES['log_latencies'] = (\n",
    "    \"CREATE TABLE `log_latencies` (\"\n",
    "    \"  `id` int(11) NOT NULL AUTO_INCREMENT,\"\n",
    "    \"  `log_id` int(11) NOT NULL,\"\n",
    "    \"  `proxy` integer(11) NOT NULL,\"\n",
    "    \"  `kong` integer(11) NOT NULL,\"\n",
    "    \"  `request` integer(11) NOT NULL,\"\n",
    "    \"  CONSTRAINT `latencie_log_fk` FOREIGN KEY (`log_id`) \"\n",
    "    \"     REFERENCES `log` (`id`) ON DELETE CASCADE,\"\n",
    "    \"  PRIMARY KEY (`id`)\"\n",
    "    \") ENGINE=InnoDB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Após estabelecer a conexão e definir as tabelas a serem criadas, vamos nos conectar no database desejado e então criar as tabelas caso não existam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para criar o database caso não exista\n",
    "def create_database(cursor):\n",
    "    try:\n",
    "        cursor.execute(\n",
    "            \"CREATE DATABASE {} DEFAULT CHARACTER SET 'utf8'\".format(DB_NAME))\n",
    "    except mysql.connector.Error as err:\n",
    "        print(\"Failed creating database: {}\".format(err))\n",
    "        exit(1)\n",
    "\n",
    "# Faz a conexão com o database desejado\n",
    "try:\n",
    "    cursor.execute(\"USE {}\".format(DB_NAME))\n",
    "    print(\"Using database {} ..........\".format(DB_NAME))\n",
    "except mysql.connector.Error as err:\n",
    "    print(\"Database {} does not exists.\".format(DB_NAME))\n",
    "    if err.errno == errorcode.ER_BAD_DB_ERROR:\n",
    "        create_database(cursor)\n",
    "        print(\"Database {} created successfully.\".format(DB_NAME))\n",
    "        cnx.database = DB_NAME\n",
    "    else:\n",
    "        print(err)\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza a criação das tabelas que não existem\n",
    "for table_name in TABLES:\n",
    "    table_description = TABLES[table_name]\n",
    "    try:\n",
    "        print(\"Creating table {}: \".format(table_name), end='')\n",
    "        cursor.execute(table_description)\n",
    "    except mysql.connector.Error as err:\n",
    "        if err.errno == errorcode.ER_TABLE_EXISTS_ERROR:\n",
    "            print(\"already exists.\")\n",
    "        else:\n",
    "            print(err.msg)\n",
    "    else:\n",
    "        print(\"OK\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"Tabelas criadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Após todas as tabelas criadas, realizamos o insert dos dados dos logs nas tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insere os dados do dataframe 1 por 1\n",
    "\n",
    "# Tabela LOG\n",
    "for i,row in df.iterrows():\n",
    "    sql = \"INSERT INTO `log` (`consumer_id`,`upstream_uri`,`client_ip`,`started_at`,`id`) VALUES (\" + \"%s,\"*(len(row)-1) + \"%s)\"\n",
    "    cursor.execute(sql, tuple(row))\n",
    "    cnx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela LOG_REQUEST\n",
    "for i,row in df_request.iterrows():\n",
    "    sql = \"INSERT INTO `log_request` (`accept`,`host`,`user_agent`,`method`,`uri`, `url`, `size`, `querystring`, `log_id`) VALUES (\" + \"%s,\"*(len(row)-1) + \"%s)\"\n",
    "    cursor.execute(sql, tuple(row))\n",
    "    cnx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela LOG_RESPONSE\n",
    "for i,row in df_response.iterrows():\n",
    "    sql = \"INSERT INTO `log_response` (`content_length`,`via`,`connection`,`access_control_allow_credentials`,`content_type`,`server`,`access_control_allow_origin`,`status`,`size`,`log_id`) VALUES (\" + \"%s,\"*(len(row)-1) + \"%s)\"\n",
    "    cursor.execute(sql, tuple(row))\n",
    "    cnx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela LOG_ROUTE\n",
    "for i,row in df_route.iterrows():\n",
    "    sql = \"INSERT INTO `log_route` (`service_id`,`created_at`,`hosts`,`route_id`,`methods`,`paths`,`preserve_host`,`protocols`,`regex_priority`,`strip_path`,`updated_at`,`log_id`) VALUES (\" + \"%s,\"*(len(row)-1) + \"%s)\"\n",
    "    cursor.execute(sql, tuple(row))\n",
    "    cnx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela LOG_SERVICE\n",
    "for i,row in df_service.iterrows():\n",
    "    sql = \"INSERT INTO `log_service` (`connect_timeout`,`created_at`,`host`,`service_id`,`name`,`path`,`port`,`protocol`,`read_timeout`,`retries`,`updated_at`,`write_timeout`,`log_id`) VALUES (\" + \"%s,\"*(len(row)-1) + \"%s)\"\n",
    "    cursor.execute(sql, tuple(row))\n",
    "    cnx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela LOG_LATENCIES\n",
    "for i,row in df_latencies.iterrows():\n",
    "    sql = \"INSERT INTO `log_latencies` (`proxy`,`kong`,`request`,`log_id`) VALUES (\" + \"%s,\"*(len(row)-1) + \"%s)\"\n",
    "    cursor.execute(sql, tuple(row))\n",
    "    cnx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar a quantidade de linhas inseridas\n",
    "for table_name in TABLES:\n",
    "    cursor.execute(\"select count(1) from {}\".format(table_name))\n",
    "    row = cursor.fetchone()\n",
    "    print(f\"Tabela {table_name} possue {row[0]} linhas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Após todos os inserts, fechamos a conexão com o banco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fecha a conexão\n",
    "cursor.close()\n",
    "cnx.close()\n",
    "print(\"Conexão encerrada com sucesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nesta parte iremos realizar a geração dos relatórios solicitados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Cria a conexão com o banco e inicializa o cursor\n",
    "    cnx = mysql.connector.connect(user='root', password='root',host='127.0.0.1')\n",
    "    cursor = cnx.cursor()\n",
    "    print(\"Conectado com sucesso\")\n",
    "    \n",
    "    # Definimos o database a ser utilizado\n",
    "    DB_NAME = 'melhor_envio'\n",
    "\n",
    "    # Faz a conexão com o database desejado\n",
    "    cursor.execute(\"USE {}\".format(DB_NAME))\n",
    "    print(\"Using database {}\".format(DB_NAME))\n",
    "    \n",
    "    # Query para o relatório de requisições por consumidor\n",
    "    sql1 = \"select a.consumer_id, a.client_ip, a.started_at, b.method, b.uri, b.url, b.size, \\\n",
    "            b.querystring, b.accept, b.host, b.user_agent from log a \\\n",
    "            inner join log_request b on (a.id = b.log_id) \\\n",
    "            order by a.consumer_id\"\n",
    "    \n",
    "    print(\"Gerando relatório de requisições por consumidor.....\")\n",
    "    \n",
    "    # Cria um dataframe com a query para gerar o relatório\n",
    "    relatorio1 = pd.read_sql(sql1, con=cnx)\n",
    "    \n",
    "    # Exporta o dataframe para um arquivo csv\n",
    "    relatorio1.to_csv(\"RelatorioRequisicoesConsumidor.csv\", index=False)\n",
    "    print(\"Relatório de requisições por consumidor gerado com sucesso! -> RelatorioRequisicoesConsumidor.csv\")\n",
    "    \n",
    "    # Query para o relatório de requisições por serviço\n",
    "    sql2 = \"select a.connect_timeout, a.created_at, a.host, a.service_id, a.name, a.path, a.port, \\\n",
    "            a.protocol, a.read_timeout, a.retries, a.updated_at, a.write_timeout, b.method, b.uri, \\\n",
    "            b.url, b.size, b.querystring, b.accept, b.host, b.user_agent from log_service a \\\n",
    "            inner join log_request b on (a.log_id = b.log_id) \\\n",
    "            order by a.service_id\"\n",
    "    \n",
    "    print(\"Gerando relatório de requisições por serviço.....\")\n",
    "    \n",
    "    # Cria um dataframe com a query para gerar o relatório\n",
    "    relatorio2 = pd.read_sql(sql2, con=cnx)\n",
    "    \n",
    "    # Exporta o dataframe para um arquivo csv\n",
    "    relatorio2.to_csv(\"RelatorioRequisicoesServico.csv\", index=False)\n",
    "    print(\"Relatório de requisições por serviço gerado com sucesso! -> RelatorioRequisicoesServico.csv\")\n",
    "    \n",
    "    # Query para o relatório tempo médio de request , proxy e kong por serviço\n",
    "    sql3 = \"select avg(b.proxy) as tempo_medio_proxy, avg(b.kong) as tempo_medio_kong, \\\n",
    "            avg(b.request) as tempo_medio_request, a.service_id from log_service a \\\n",
    "            inner join log_latencies b on (a.log_id = b.log_id) \\\n",
    "            group by a.service_id order by a.service_id\"\n",
    "    \n",
    "    print(\"Gerando relatório de requisições por serviço.....\")\n",
    "    \n",
    "    # Cria um dataframe com a query para gerar o relatório\n",
    "    relatorio3 = pd.read_sql(sql3, con=cnx)\n",
    "    \n",
    "    # Exporta o dataframe para um arquivo csv\n",
    "    relatorio3.to_csv(\"RelatorioLatenciesServico.csv\", index=False)\n",
    "    print(\"Relatório de tempo médio de request, proxy e kong por serviço gerado com sucesso! -> RelatorioLatenciesServico.csv\")\n",
    "    \n",
    "except mysql.connector.Error as err:\n",
    "    print(\"Erro : \",err)\n",
    "finally:\n",
    "    cursor.close()\n",
    "    cnx.close()\n",
    "    print(\"Conexão encerrada com sucesso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
